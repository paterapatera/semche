# ユーザーは類似性検索を廃止して代わりにハイブリット検索ができるようになる

## 概要

現在の検索機能はLangChainのChromaベクトルストアによる密ベクトル検索（dense vector search）のみを提供していますが、これをハイブリッド検索（dense + sparse）に置き換えます。ハイブリッド検索により、セマンティック検索（意味的類似性）とキーワード検索（語彙的一致）の両方の利点を活用でき、より高精度な検索結果を提供できます。

## 実行手順(上から順にチェックしてください)

### Phase 1: 要件定義・設計【対話フェーズ - ユーザー確認必須】

- [x] ストーリーの背景と目的を確認する
  - 現状: Dense vector searchのみ（semantic similarity）
  - 課題: キーワードベースの検索が弱い、専門用語や固有名詞の検索精度が低い
  - 目的: ハイブリッド検索（dense + sparse）により、セマンティック検索とキーワード検索を組み合わせて検索精度を向上
- [x] 実装する機能の詳細をユーザーと対話して決定する
  - ✅ **確定**: LangChain EnsembleRetriever + BM25 + RRF
  - ✅ **確定**: スパースエンコーダはBM25（軽量、多言語対応）
  - ✅ **確定**: スコア統合はRRF（Reciprocal Rank Fusion）
  - ✅ **確定**: 後方互換性は不要、ハイブリッド検索のみに完全移行
  - ✅ **確定**: パフォーマンス150-300msは許容範囲
  - ✅ **確定**: 段階的移行は不要、最初からハイブリッドのみ
- [x] 技術スタック（使用するライブラリ・フレームワーク）をユーザーと相談する
  - ✅ LangChain EnsembleRetriever: 複数のretrieverを統合
  - ✅ BM25 (rank-bm25): 軽量、多言語対応
  - ✅ RRF: LangChainのデフォルトスコア統合方式
  - ✅ ChromaDB: 既存のdense vectorストレージ（継続使用）
  - ✅ 重み設定: 50:50（均等配分、`weights=[0.5, 0.5]`で固定）
- [x] ファイル構成案を提示し、ユーザーの承認を得る
  - 新規作成: `src/semche/sparse_encoder.py` - BM25エンコーダの実装
  - 新規作成: `src/semche/sparse_encoder.py.exp.md` - 詳細設計書
  - 新規作成: `src/semche/hybrid_retriever.py` - ハイブリッド検索の実装
  - 新規作成: `src/semche/hybrid_retriever.py.exp.md` - 詳細設計書
  - 修正対象: `src/semche/chromadb_manager.py` - 全ドキュメント取得API追加
  - 修正対象: `src/semche/tools/search.py` - ハイブリッド検索に完全移行
  - 修正対象: `src/semche/tools/search.py.exp.md` - 詳細設計書更新
  - テスト: `tests/test_sparse_encoder.py` - 新規作成
  - テスト: `tests/test_hybrid_retriever.py` - 新規作成
  - テスト: `tests/test_search.py` - 既存テスト更新
  - ドキュメント: `README.md`, `AGENTS.md` - ハイブリッド検索について記載
  - 依存関係: `pyproject.toml` - rank-bm25, langchain-community追加
- [x] **Phase 1完了の確認をユーザーから得てから次に進む** ✅ 承認済み
- [x] 承認を得た内容をストーリーに反映する

### Phase 2: 実装【実装フェーズ】

- [x] スパースエンコーダの実装 (`src/semche/sparse_encoder.py`)
  - BM25エンコーダクラスの作成
  - インデックス構築機能（ドキュメント追加時）
  - クエリエンコーディング機能
  - スコア計算機能
  - 永続化対応（インデックスの保存・読み込み）
- [x] ハイブリッドリトリーバーの実装 (`src/semche/hybrid_retriever.py`)
  - EnsembleRetriever非依存のRRF実装（互換性のため）
  - Dense + Sparseの重み付け設定（50:50固定）
  - スコア統合ロジック（RRF）
  - メタデータフィルタリング対応
  - top_kパラメータ対応
- [x] ChromaDBManagerの拡張（必要に応じて）
  - スパースインデックスとの連携
  - 全ドキュメント取得API（sparse indexing用）
  - バッチ処理対応
- [x] searchツールの更新 (`src/semche/tools/search.py`)
  - ハイブリッド検索のみへ完全移行（後方互換なし）
  - 既存の引数（query/top_k/file_type/include_documents）は維持
  - エラーハンドリング
- [ ] CLIツールの更新（必要に応じて）
  - `doc-update`でスパースインデックスも更新
  - インデックス再構築コマンド追加検討
- [x] 依存関係の追加
  - `pyproject.toml`に必要なライブラリを追加
  - 例: `rank-bm25`, `langchain-community`など
- [x] コア機能の実装が完了している
- [x] `CODE_REVIEW_GUIDE.md` に準拠してコードレビューが完了している
- [x] テストコードが作成されている
  - スパースエンコーダの単体テスト
  - ハイブリッドリトリーバーの単体テスト
  - searchツールの統合テスト
  - パフォーマンステスト
- [x] テストが全てパスする
- [x] Lint（ruff）/ 型チェック（mypy）が通る
- [x] README.md と詳細設計書（`.exp.md`）を更新済み
  - ハイブリッド検索の説明追加
  - 使用例とパラメータ説明
  - パフォーマンス特性の記載
  - **日本語対応（MeCab + unidic-lite）の記載**

### Phase 3: 確認・ドキュメント【対話フェーズ - ユーザー確認必須】

- [ ] 実装完了を報告し、ユーザーにレビューを依頼する
- [ ] 手動での動作確認を行う
  - MCP Inspectorで`search`ツールをテスト
  - Dense onlyとHybridの検索結果を比較
  - キーワード検索の精度向上を確認
  - レスポンス時間を測定
- [ ] 今回更新したコードの詳細設計書を更新する
  - 各新規ファイルの`.exp.md`を作成
  - 既存ファイルの`.exp.md`を更新
- [ ] **全ての作業完了をユーザーに報告する**

## 技術メモ

### ハイブリッド検索とは

ハイブリッド検索は、以下の2つのアプローチを組み合わせます：

1. **Dense Vector Search (密ベクトル検索)**
   - セマンティック検索（意味的類似性）
   - 類似した意味を持つドキュメントを検索
   - 現在実装済み（LangChain Chroma）

2. **Sparse Vector Search (疎ベクトル検索)**
   - キーワードベース検索（語彙的一致）
   - BM25、TF-IDFなどの従来の情報検索手法
   - 専門用語や固有名詞に強い

### 実装方式の選択肢

#### オプション1: LangChain EnsembleRetriever（推奨）

> **注記:** 本プロジェクトの実装では、LangChainの`BM25Retriever`や`EnsembleRetriever`はAPI互換性・安定性の観点から未使用です。代わりに、独自実装のBM25（`src/semche/sparse_encoder.py`）とRRF統合（`src/semche/hybrid_retriever.py`）を採用しています。下記は参考例です。

```python
from langchain.retrievers import EnsembleRetriever
from langchain_chroma import Chroma
from langchain_community.retrievers import BM25Retriever

# Dense retriever（既存）
dense_retriever = Chroma(
    client=chroma_client,
    collection_name="documents",
    embedding_function=embedder.embeddings
).as_retriever(search_kwargs={"k": top_k})

# Sparse retriever（新規）
sparse_retriever = BM25Retriever.from_documents(
    documents=all_documents,
    k=top_k
)

# Ensemble retriever
ensemble_retriever = EnsembleRetriever(
    retrievers=[dense_retriever, sparse_retriever],
    weights=[0.5, 0.5],  # 重み調整可能
    c=60  # RRF constant
)

# 検索
results = ensemble_retriever.get_relevant_documents(query)
```

**メリット**:

- LangChainの標準機能を活用
- RRF（Reciprocal Rank Fusion）による高精度なスコア統合
- メンテナンスが容易

**デメリット**:

- LangChainへの依存度が高まる
- カスタマイズの自由度が低い

#### オプション2: カスタム実装

```python
class HybridRetriever:
    def __init__(self, dense_retriever, sparse_retriever, alpha=0.5):
        self.dense = dense_retriever
        self.sparse = sparse_retriever
        self.alpha = alpha  # dense weight (0.0-1.0)

    def search(self, query, k=5):
        # Dense search
        dense_results = self.dense.search(query, k=k*2)

        # Sparse search
        sparse_results = self.sparse.search(query, k=k*2)

        # Merge and re-rank
        merged = self._merge_results(dense_results, sparse_results)
        return merged[:k]

    def _merge_results(self, dense, sparse):
        # Weighted score combination or RRF
        ...
```

**メリット**:

- 完全なコントロール
- パフォーマンス最適化が可能
- LangChainへの依存が少ない

**デメリット**:

- 実装コストが高い
- スコア統合ロジックの正確性を担保する必要

### スパースエンコーダの選択

#### BM25（推奨）

```python
from rank_bm25 import BM25Okapi

# インデックス構築
corpus = [doc.split() for doc in documents]  # トークン化
bm25 = BM25Okapi(corpus)

# 検索
query_tokens = query.split()
scores = bm25.get_scores(query_tokens)
top_indices = scores.argsort()[-k:][::-1]
```

**メリット**:

- 軽量、高速
- 多言語対応
- 実績が豊富

**デメリット**:

- トークン化の品質に依存
- 意味的類似性は捉えられない

#### SPLADE

```python
from transformers import AutoModelForMaskedLM, AutoTokenizer

# ニューラルスパースエンコーディング
model = AutoModelForMaskedLM.from_pretrained("naver/splade-cocondenser-ensembledistil")
tokenizer = AutoTokenizer.from_pretrained("naver/splade-cocondenser-ensembledistil")

# エンコーディング
sparse_vector = encode_splade(text)
```

**メリット**:

- 高精度
- 学習されたスパース表現

**デメリット**:

- 重い（推論時間）
- メモリ消費が大きい
- モデルダウンロードが必要

### スコア統合方法

#### Weighted Average（重み付け平均）

```python
final_score = alpha * dense_score + (1 - alpha) * sparse_score
```

- シンプル
- スコアの正規化が必要

#### RRF (Reciprocal Rank Fusion)

```python
score(doc) = sum(1 / (k + rank_i(doc)))
```

- スコアの正規化不要
- ランクベースの統合（より堅牢）
- LangChain EnsembleRetrieverのデフォルト

### パフォーマンス考慮事項

1. **インデックス構築**
   - スパースインデックスの構築時間
   - ドキュメント追加時の更新コスト
   - 永続化戦略

2. **検索時間**
   - Dense: ~50-200ms（ベクトル検索）
   - Sparse: ~10-50ms（BM25）
   - 合計: ~100-300ms（並列化可能）

3. **メモリ使用量**
   - BM25インデックス: ドキュメント数に比例
   - SPLADE: モデルサイズ（~500MB）+ インデックス

### 互換性の維持

既存の`search`ツールAPIを維持：

```python
def search(
    query: str,
    top_k: int = 5,
    file_type: str | None = None,
    include_documents: bool = True,
    # 新規パラメータ（後方互換性あり）
    use_hybrid: bool = True,  # Falseで従来のdense onlyに戻せる
    dense_weight: float = 0.5,  # dense vs sparseの重み（0.0-1.0）
) -> dict:
    ...
```

### 段階的な移行戦略

1. **Phase 2.1**: スパースエンコーダのみ実装・テスト
2. **Phase 2.2**: ハイブリッドリトリーバー実装（オプション機能として）
3. **Phase 2.3**: デフォルトをハイブリッドに変更
4. **Phase 2.4**: パフォーマンスチューニング

### リスクと対策

| リスク           | 影響 | 対策                       |
| ---------------- | ---- | -------------------------- |
| 検索速度の低下   | 高   | 並列化、キャッシング       |
| メモリ使用量増加 | 中   | BM25選択、遅延ロード       |
| 既存機能の破壊   | 高   | 後方互換性維持、段階的移行 |
| 検索精度が下がる | 中   | A/Bテスト、重み調整機能    |

### 期待される効果

- キーワード検索の精度向上（専門用語、固有名詞）
- セマンティック検索の利点も維持
- より柔軟な検索体験（重み調整可能）
- 将来的な拡張性（3つ以上のretrieverも可能）

### 参考資料

- [LangChain EnsembleRetriever](https://python.langchain.com/docs/integrations/retrievers/ensemble)
- [BM25 Algorithm](https://en.wikipedia.org/wiki/Okapi_BM25)
- [SPLADE Models](https://github.com/naver/splade)
- [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)
